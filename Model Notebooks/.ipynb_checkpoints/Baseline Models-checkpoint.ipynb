{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "Created various models using these machine learning techniques to evaluate which ones to use moving forward.\n",
    "\n",
    "### Classification (Classify a Winner, Loser, or if both teams Drew)\n",
    "\n",
    "* Logistic Regression\n",
    "* Decision Tree\n",
    "* Random Forest\n",
    "* K Nearest Neighbors\n",
    "* Stochastic Gradient Descent\n",
    "* Naive Bayes\n",
    "* Neural Network (Multi Layer Perceptron)\n",
    "* Ensemble Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Processing\n",
    "import pandas as pd\n",
    "\n",
    "# ML Algorithms\n",
    "## Classification Algorithms\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import VotingClassifier # Ensemble Classifier\n",
    "\n",
    "## Regression Algorithms\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn import svm\n",
    "\n",
    "# ML Tools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# ML Evaluation/Metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loads Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:/Users/Jake/Desktop/Notebooks/EPL Prediction Model/Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Season Encoding</th>\n",
       "      <th>Date</th>\n",
       "      <th>YearOfSeason</th>\n",
       "      <th>YearOfSeason Encoding</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>HomeTeam Encoding</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>AwayTeam Encoding</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>...</th>\n",
       "      <th>HST</th>\n",
       "      <th>AST</th>\n",
       "      <th>HF</th>\n",
       "      <th>AF</th>\n",
       "      <th>HC</th>\n",
       "      <th>AC</th>\n",
       "      <th>HY</th>\n",
       "      <th>AY</th>\n",
       "      <th>HR</th>\n",
       "      <th>AR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fall</td>\n",
       "      <td>0</td>\n",
       "      <td>12/09/2020</td>\n",
       "      <td>2020/21</td>\n",
       "      <td>1</td>\n",
       "      <td>Fulham</td>\n",
       "      <td>8</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fall</td>\n",
       "      <td>0</td>\n",
       "      <td>12/09/2020</td>\n",
       "      <td>2020/21</td>\n",
       "      <td>1</td>\n",
       "      <td>Crystal Palace</td>\n",
       "      <td>6</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fall</td>\n",
       "      <td>0</td>\n",
       "      <td>12/09/2020</td>\n",
       "      <td>2020/21</td>\n",
       "      <td>1</td>\n",
       "      <td>Liverpool</td>\n",
       "      <td>13</td>\n",
       "      <td>Leeds</td>\n",
       "      <td>11</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fall</td>\n",
       "      <td>0</td>\n",
       "      <td>12/09/2020</td>\n",
       "      <td>2020/21</td>\n",
       "      <td>1</td>\n",
       "      <td>West Ham</td>\n",
       "      <td>28</td>\n",
       "      <td>Newcastle</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fall</td>\n",
       "      <td>0</td>\n",
       "      <td>13/09/2020</td>\n",
       "      <td>2020/21</td>\n",
       "      <td>1</td>\n",
       "      <td>West Brom</td>\n",
       "      <td>27</td>\n",
       "      <td>Leicester</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2564</th>\n",
       "      <td>Spring</td>\n",
       "      <td>2</td>\n",
       "      <td>14/03/15</td>\n",
       "      <td>2014/15</td>\n",
       "      <td>7</td>\n",
       "      <td>West Brom</td>\n",
       "      <td>27</td>\n",
       "      <td>Stoke</td>\n",
       "      <td>22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2565</th>\n",
       "      <td>Spring</td>\n",
       "      <td>2</td>\n",
       "      <td>15/03/15</td>\n",
       "      <td>2014/15</td>\n",
       "      <td>7</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>5</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2566</th>\n",
       "      <td>Spring</td>\n",
       "      <td>2</td>\n",
       "      <td>15/03/15</td>\n",
       "      <td>2014/15</td>\n",
       "      <td>7</td>\n",
       "      <td>Everton</td>\n",
       "      <td>7</td>\n",
       "      <td>Newcastle</td>\n",
       "      <td>17</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2567</th>\n",
       "      <td>Spring</td>\n",
       "      <td>2</td>\n",
       "      <td>15/03/15</td>\n",
       "      <td>2014/15</td>\n",
       "      <td>7</td>\n",
       "      <td>Man United</td>\n",
       "      <td>15</td>\n",
       "      <td>Tottenham</td>\n",
       "      <td>25</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2568</th>\n",
       "      <td>Spring</td>\n",
       "      <td>2</td>\n",
       "      <td>16/03/15</td>\n",
       "      <td>2014/15</td>\n",
       "      <td>7</td>\n",
       "      <td>Swansea</td>\n",
       "      <td>24</td>\n",
       "      <td>Liverpool</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Season  Season Encoding        Date YearOfSeason  YearOfSeason Encoding  \\\n",
       "0       Fall                0  12/09/2020      2020/21                      1   \n",
       "1       Fall                0  12/09/2020      2020/21                      1   \n",
       "2       Fall                0  12/09/2020      2020/21                      1   \n",
       "3       Fall                0  12/09/2020      2020/21                      1   \n",
       "4       Fall                0  13/09/2020      2020/21                      1   \n",
       "...      ...              ...         ...          ...                    ...   \n",
       "2564  Spring                2    14/03/15      2014/15                      7   \n",
       "2565  Spring                2    15/03/15      2014/15                      7   \n",
       "2566  Spring                2    15/03/15      2014/15                      7   \n",
       "2567  Spring                2    15/03/15      2014/15                      7   \n",
       "2568  Spring                2    16/03/15      2014/15                      7   \n",
       "\n",
       "            HomeTeam  HomeTeam Encoding     AwayTeam  AwayTeam Encoding  FTHG  \\\n",
       "0             Fulham                  8      Arsenal                  0   0.0   \n",
       "1     Crystal Palace                  6  Southampton                 21   1.0   \n",
       "2          Liverpool                 13        Leeds                 11   4.0   \n",
       "3           West Ham                 28    Newcastle                 17   0.0   \n",
       "4          West Brom                 27    Leicester                 12   0.0   \n",
       "...              ...                ...          ...                ...   ...   \n",
       "2564       West Brom                 27        Stoke                 22   1.0   \n",
       "2565         Chelsea                  5  Southampton                 21   1.0   \n",
       "2566         Everton                  7    Newcastle                 17   3.0   \n",
       "2567      Man United                 15    Tottenham                 25   3.0   \n",
       "2568         Swansea                 24    Liverpool                 13   0.0   \n",
       "\n",
       "      ...  HST  AST    HF    AF   HC   AC   HY   AY   HR   AR  \n",
       "0     ...  2.0  6.0  12.0  12.0  2.0  3.0  2.0  2.0  0.0  0.0  \n",
       "1     ...  3.0  5.0  14.0  11.0  7.0  3.0  2.0  1.0  0.0  0.0  \n",
       "2     ...  6.0  3.0   9.0   6.0  9.0  0.0  1.0  0.0  0.0  0.0  \n",
       "3     ...  3.0  2.0  13.0   7.0  8.0  7.0  2.0  2.0  0.0  0.0  \n",
       "4     ...  1.0  7.0  12.0   9.0  2.0  5.0  1.0  1.0  0.0  0.0  \n",
       "...   ...  ...  ...   ...   ...  ...  ...  ...  ...  ...  ...  \n",
       "2564  ...  5.0  2.0   7.0  16.0  7.0  5.0  1.0  2.0  0.0  0.0  \n",
       "2565  ...  7.0  5.0  10.0  11.0  9.0  2.0  3.0  3.0  0.0  0.0  \n",
       "2566  ...  9.0  4.0  11.0   9.0  3.0  4.0  1.0  2.0  0.0  1.0  \n",
       "2567  ...  3.0  1.0  12.0  10.0  4.0  2.0  1.0  1.0  0.0  0.0  \n",
       "2568  ...  3.0  5.0  13.0  16.0  4.0  5.0  0.0  3.0  0.0  0.0  \n",
       "\n",
       "[2569 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path + '/Encoded_EPL_Data.csv')\n",
    "\n",
    "# Had this column get created upon loading, just dropped it\n",
    "df = df.drop(columns=[\"Unnamed: 0\"]) \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Season Encoding</th>\n",
       "      <th>Date</th>\n",
       "      <th>YearOfSeason</th>\n",
       "      <th>Time</th>\n",
       "      <th>Time Encoding</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>HomeTeam Encoding</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>AwayTeam Encoding</th>\n",
       "      <th>...</th>\n",
       "      <th>HST</th>\n",
       "      <th>AST</th>\n",
       "      <th>HF</th>\n",
       "      <th>AF</th>\n",
       "      <th>HC</th>\n",
       "      <th>AC</th>\n",
       "      <th>HY</th>\n",
       "      <th>AY</th>\n",
       "      <th>HR</th>\n",
       "      <th>AR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fall</td>\n",
       "      <td>0</td>\n",
       "      <td>12/09/2020</td>\n",
       "      <td>2020/21</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>0</td>\n",
       "      <td>Fulham</td>\n",
       "      <td>8</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fall</td>\n",
       "      <td>0</td>\n",
       "      <td>12/09/2020</td>\n",
       "      <td>2020/21</td>\n",
       "      <td>Late-Day</td>\n",
       "      <td>2</td>\n",
       "      <td>Crystal Palace</td>\n",
       "      <td>6</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fall</td>\n",
       "      <td>0</td>\n",
       "      <td>12/09/2020</td>\n",
       "      <td>2020/21</td>\n",
       "      <td>Late-Day</td>\n",
       "      <td>2</td>\n",
       "      <td>Liverpool</td>\n",
       "      <td>13</td>\n",
       "      <td>Leeds</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fall</td>\n",
       "      <td>0</td>\n",
       "      <td>12/09/2020</td>\n",
       "      <td>2020/21</td>\n",
       "      <td>Late-Day</td>\n",
       "      <td>2</td>\n",
       "      <td>West Ham</td>\n",
       "      <td>28</td>\n",
       "      <td>Newcastle</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fall</td>\n",
       "      <td>0</td>\n",
       "      <td>13/09/2020</td>\n",
       "      <td>2020/21</td>\n",
       "      <td>Mid-Day</td>\n",
       "      <td>1</td>\n",
       "      <td>West Brom</td>\n",
       "      <td>27</td>\n",
       "      <td>Leicester</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>Summer</td>\n",
       "      <td>3</td>\n",
       "      <td>26/07/2020</td>\n",
       "      <td>2019/20</td>\n",
       "      <td>Mid-Day</td>\n",
       "      <td>1</td>\n",
       "      <td>Leicester</td>\n",
       "      <td>12</td>\n",
       "      <td>Man United</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>Summer</td>\n",
       "      <td>3</td>\n",
       "      <td>26/07/2020</td>\n",
       "      <td>2019/20</td>\n",
       "      <td>Mid-Day</td>\n",
       "      <td>1</td>\n",
       "      <td>Man City</td>\n",
       "      <td>14</td>\n",
       "      <td>Norwich</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>Summer</td>\n",
       "      <td>3</td>\n",
       "      <td>26/07/2020</td>\n",
       "      <td>2019/20</td>\n",
       "      <td>Mid-Day</td>\n",
       "      <td>1</td>\n",
       "      <td>Newcastle</td>\n",
       "      <td>17</td>\n",
       "      <td>Liverpool</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>Summer</td>\n",
       "      <td>3</td>\n",
       "      <td>26/07/2020</td>\n",
       "      <td>2019/20</td>\n",
       "      <td>Mid-Day</td>\n",
       "      <td>1</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>21</td>\n",
       "      <td>Sheffield United</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>Summer</td>\n",
       "      <td>3</td>\n",
       "      <td>26/07/2020</td>\n",
       "      <td>2019/20</td>\n",
       "      <td>Mid-Day</td>\n",
       "      <td>1</td>\n",
       "      <td>West Ham</td>\n",
       "      <td>28</td>\n",
       "      <td>Aston Villa</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>760 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Season  Season Encoding        Date YearOfSeason       Time  \\\n",
       "0      Fall                0  12/09/2020      2020/21  Afternoon   \n",
       "1      Fall                0  12/09/2020      2020/21   Late-Day   \n",
       "2      Fall                0  12/09/2020      2020/21   Late-Day   \n",
       "3      Fall                0  12/09/2020      2020/21   Late-Day   \n",
       "4      Fall                0  13/09/2020      2020/21    Mid-Day   \n",
       "..      ...              ...         ...          ...        ...   \n",
       "755  Summer                3  26/07/2020      2019/20    Mid-Day   \n",
       "756  Summer                3  26/07/2020      2019/20    Mid-Day   \n",
       "757  Summer                3  26/07/2020      2019/20    Mid-Day   \n",
       "758  Summer                3  26/07/2020      2019/20    Mid-Day   \n",
       "759  Summer                3  26/07/2020      2019/20    Mid-Day   \n",
       "\n",
       "     Time Encoding        HomeTeam  HomeTeam Encoding          AwayTeam  \\\n",
       "0                0          Fulham                  8           Arsenal   \n",
       "1                2  Crystal Palace                  6       Southampton   \n",
       "2                2       Liverpool                 13             Leeds   \n",
       "3                2        West Ham                 28         Newcastle   \n",
       "4                1       West Brom                 27         Leicester   \n",
       "..             ...             ...                ...               ...   \n",
       "755              1       Leicester                 12        Man United   \n",
       "756              1        Man City                 14           Norwich   \n",
       "757              1       Newcastle                 17         Liverpool   \n",
       "758              1     Southampton                 21  Sheffield United   \n",
       "759              1        West Ham                 28       Aston Villa   \n",
       "\n",
       "     AwayTeam Encoding  ...   HST  AST    HF    AF   HC   AC   HY   AY   HR  \\\n",
       "0                    0  ...   2.0  6.0  12.0  12.0  2.0  3.0  2.0  2.0  0.0   \n",
       "1                   21  ...   3.0  5.0  14.0  11.0  7.0  3.0  2.0  1.0  0.0   \n",
       "2                   11  ...   6.0  3.0   9.0   6.0  9.0  0.0  1.0  0.0  0.0   \n",
       "3                   17  ...   3.0  2.0  13.0   7.0  8.0  7.0  2.0  2.0  0.0   \n",
       "4                   12  ...   1.0  7.0  12.0   9.0  2.0  5.0  1.0  1.0  0.0   \n",
       "..                 ...  ...   ...  ...   ...   ...  ...  ...  ...  ...  ...   \n",
       "755                 15  ...   3.0  3.0  12.0  11.0  3.0  3.0  1.0  4.0  1.0   \n",
       "756                 18  ...  10.0  4.0   7.0   4.0  9.0  0.0  1.0  1.0  0.0   \n",
       "757                 13  ...   2.0  6.0  11.0   5.0  2.0  4.0  1.0  0.0  0.0   \n",
       "758                 20  ...   4.0  3.0   9.0  16.0  9.0  1.0  0.0  1.0  0.0   \n",
       "759                 -1  ...   1.0  4.0  16.0  13.0  0.0  7.0  2.0  1.0  0.0   \n",
       "\n",
       "      AR  \n",
       "0    0.0  \n",
       "1    0.0  \n",
       "2    0.0  \n",
       "3    0.0  \n",
       "4    0.0  \n",
       "..   ...  \n",
       "755  0.0  \n",
       "756  0.0  \n",
       "757  0.0  \n",
       "758  0.0  \n",
       "759  0.0  \n",
       "\n",
       "[760 rows x 32 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_df = pd.read_csv(path + '/Encoded_EPL_DataWithTime.csv')\n",
    "\n",
    "# Had this column get created upon loading, just dropped it\n",
    "time_df = time_df.drop(columns=[\"Unnamed: 0\"]) \n",
    "time_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal Dataset (Excludes Time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splits the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2569 entries, 0 to 2568\n",
      "Data columns (total 31 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Season                 2569 non-null   object \n",
      " 1   Season Encoding        2569 non-null   int64  \n",
      " 2   Date                   2569 non-null   object \n",
      " 3   YearOfSeason           2338 non-null   object \n",
      " 4   YearOfSeason Encoding  2569 non-null   int64  \n",
      " 5   HomeTeam               2569 non-null   object \n",
      " 6   HomeTeam Encoding      2569 non-null   int64  \n",
      " 7   AwayTeam               2569 non-null   object \n",
      " 8   AwayTeam Encoding      2569 non-null   int64  \n",
      " 9   FTHG                   2569 non-null   float64\n",
      " 10  FTAG                   2569 non-null   float64\n",
      " 11  FTR                    2569 non-null   object \n",
      " 12  FTR Encoding           2569 non-null   int64  \n",
      " 13  HTHG                   2569 non-null   float64\n",
      " 14  HTAG                   2569 non-null   float64\n",
      " 15  HTR                    2569 non-null   object \n",
      " 16  Referee                2569 non-null   object \n",
      " 17  Referee Encoding       2569 non-null   int64  \n",
      " 18  Fouls Called Per Game  2569 non-null   float64\n",
      " 19  HS                     2569 non-null   float64\n",
      " 20  AS                     2569 non-null   float64\n",
      " 21  HST                    2569 non-null   float64\n",
      " 22  AST                    2569 non-null   float64\n",
      " 23  HF                     2569 non-null   float64\n",
      " 24  AF                     2569 non-null   float64\n",
      " 25  HC                     2569 non-null   float64\n",
      " 26  AC                     2569 non-null   float64\n",
      " 27  HY                     2569 non-null   float64\n",
      " 28  AY                     2569 non-null   float64\n",
      " 29  HR                     2569 non-null   float64\n",
      " 30  AR                     2569 non-null   float64\n",
      "dtypes: float64(17), int64(6), object(8)\n",
      "memory usage: 622.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features -- Drops FTR and any categorical value \n",
    "X = df.drop(columns=[\"Season\", \"YearOfSeason\", \"Date\", \"FTHG\",\"FTAG\" , \"HTHG\",\"HTAG\" ,\"HomeTeam\", \"AwayTeam\", \"Referee\", \"FTR\", \"FTR Encoding\", \"HTR\", \"Referee\"])\n",
    "\n",
    "# Labels\n",
    "y = df[\"FTR Encoding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2569 entries, 0 to 2568\n",
      "Data columns (total 18 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Season Encoding        2569 non-null   int64  \n",
      " 1   YearOfSeason Encoding  2569 non-null   int64  \n",
      " 2   HomeTeam Encoding      2569 non-null   int64  \n",
      " 3   AwayTeam Encoding      2569 non-null   int64  \n",
      " 4   Referee Encoding       2569 non-null   int64  \n",
      " 5   Fouls Called Per Game  2569 non-null   float64\n",
      " 6   HS                     2569 non-null   float64\n",
      " 7   AS                     2569 non-null   float64\n",
      " 8   HST                    2569 non-null   float64\n",
      " 9   AST                    2569 non-null   float64\n",
      " 10  HF                     2569 non-null   float64\n",
      " 11  AF                     2569 non-null   float64\n",
      " 12  HC                     2569 non-null   float64\n",
      " 13  AC                     2569 non-null   float64\n",
      " 14  HY                     2569 non-null   float64\n",
      " 15  AY                     2569 non-null   float64\n",
      " 16  HR                     2569 non-null   float64\n",
      " 17  AR                     2569 non-null   float64\n",
      "dtypes: float64(13), int64(5)\n",
      "memory usage: 361.4 KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season Encoding</th>\n",
       "      <th>YearOfSeason Encoding</th>\n",
       "      <th>HomeTeam Encoding</th>\n",
       "      <th>AwayTeam Encoding</th>\n",
       "      <th>Referee Encoding</th>\n",
       "      <th>Fouls Called Per Game</th>\n",
       "      <th>HS</th>\n",
       "      <th>AS</th>\n",
       "      <th>HST</th>\n",
       "      <th>AST</th>\n",
       "      <th>HF</th>\n",
       "      <th>AF</th>\n",
       "      <th>HC</th>\n",
       "      <th>AC</th>\n",
       "      <th>HY</th>\n",
       "      <th>AY</th>\n",
       "      <th>HR</th>\n",
       "      <th>AR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>28</td>\n",
       "      <td>14.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2564</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>22</td>\n",
       "      <td>28</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2565</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>14.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2566</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2567</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2568</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>13</td>\n",
       "      <td>26</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2569 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Season Encoding  YearOfSeason Encoding  HomeTeam Encoding  \\\n",
       "0                   0                      1                  8   \n",
       "1                   0                      1                  6   \n",
       "2                   0                      1                 13   \n",
       "3                   0                      1                 28   \n",
       "4                   0                      1                 27   \n",
       "...               ...                    ...                ...   \n",
       "2564                2                      7                 27   \n",
       "2565                2                      7                  5   \n",
       "2566                2                      7                  7   \n",
       "2567                2                      7                 15   \n",
       "2568                2                      7                 24   \n",
       "\n",
       "      AwayTeam Encoding  Referee Encoding  Fouls Called Per Game    HS    AS  \\\n",
       "0                     0                 7                   14.0   5.0  13.0   \n",
       "1                    21                27                   14.0   5.0   9.0   \n",
       "2                    11                28                   14.0  22.0   6.0   \n",
       "3                    17                11                   14.0  15.0  15.0   \n",
       "4                    12                10                   15.0   7.0  13.0   \n",
       "...                 ...               ...                    ...   ...   ...   \n",
       "2564                 22                28                   14.0  14.0   9.0   \n",
       "2565                 21                23                   14.0  22.0  12.0   \n",
       "2566                 17                16                   13.0  15.0  12.0   \n",
       "2567                 25                30                   14.0  11.0   5.0   \n",
       "2568                 13                26                   14.0  10.0  16.0   \n",
       "\n",
       "      HST  AST    HF    AF   HC   AC   HY   AY   HR   AR  \n",
       "0     2.0  6.0  12.0  12.0  2.0  3.0  2.0  2.0  0.0  0.0  \n",
       "1     3.0  5.0  14.0  11.0  7.0  3.0  2.0  1.0  0.0  0.0  \n",
       "2     6.0  3.0   9.0   6.0  9.0  0.0  1.0  0.0  0.0  0.0  \n",
       "3     3.0  2.0  13.0   7.0  8.0  7.0  2.0  2.0  0.0  0.0  \n",
       "4     1.0  7.0  12.0   9.0  2.0  5.0  1.0  1.0  0.0  0.0  \n",
       "...   ...  ...   ...   ...  ...  ...  ...  ...  ...  ...  \n",
       "2564  5.0  2.0   7.0  16.0  7.0  5.0  1.0  2.0  0.0  0.0  \n",
       "2565  7.0  5.0  10.0  11.0  9.0  2.0  3.0  3.0  0.0  0.0  \n",
       "2566  9.0  4.0  11.0   9.0  3.0  4.0  1.0  2.0  0.0  1.0  \n",
       "2567  3.0  1.0  12.0  10.0  4.0  2.0  1.0  1.0  0.0  0.0  \n",
       "2568  3.0  5.0  13.0  16.0  4.0  5.0  0.0  3.0  0.0  0.0  \n",
       "\n",
       "[2569 rows x 18 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       0\n",
       "2       0\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "2564    0\n",
       "2565    2\n",
       "2566    0\n",
       "2567    0\n",
       "2568    1\n",
       "Name: FTR Encoding, Length: 2569, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scales the Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "Helpful links:\n",
    "\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "\n",
    "* https://medium.com/analytics-vidhya/l1-vs-l2-regularization-which-is-better-d01068e6658c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6186770428015564\n"
     ]
    }
   ],
   "source": [
    "log_clf = LogisticRegression(random_state=42, penalty='l2', solver='sag', multi_class='ovr')\n",
    "log_clf = log_clf.fit(X_train, y_train)\n",
    "\n",
    "score = log_clf.score(X_test, y_test)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "# Compares the real result to the predicted result\n",
    "\n",
    "print(y_test.values[1])\n",
    "print(log_clf.predict([X_test[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5510007  0.18560573 0.26339358]]\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# Takes a look at all of the probabilities for the three classes/outcomes\n",
    "\n",
    "print(log_clf.predict_proba([X_test[1]]))\n",
    "print(log_clf.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.63211679 0.58978102 0.60291971] \n",
      "\n",
      "[[742 138  33]\n",
      " [162 461  35]\n",
      " [261 176  47]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "\n",
    "cv_score = cross_val_score(log_clf, X_train, y_train, cv=3, scoring='accuracy')\n",
    "\n",
    "print(cv_score, '\\n')\n",
    "\n",
    "y_train_pred = cross_val_predict(log_clf, X_train, y_train, cv=3)\n",
    "print(confusion_matrix(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.81      0.71       913\n",
      "           1       0.59      0.70      0.64       658\n",
      "           2       0.41      0.10      0.16       484\n",
      "\n",
      "    accuracy                           0.61      2055\n",
      "   macro avg       0.55      0.54      0.50      2055\n",
      "weighted avg       0.57      0.61      0.56      2055\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Precision, Recall, F1\n",
    "\n",
    "print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees\n",
    "\n",
    "Helpful Links:\n",
    "\n",
    "* https://scikit-learn.org/stable/modules/tree.html\n",
    "\n",
    "* https://scikit-learn.org/stable/modules/tree.html#classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5369649805447471\n"
     ]
    }
   ],
   "source": [
    "tree_clf = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "tree_clf.fit(X_train,y_train)\n",
    "\n",
    "score = tree_clf.score(X_test, y_test)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "# Compares the real result to the predicted result\n",
    "\n",
    "print(y_test.values[1])\n",
    "print(tree_clf.predict([X_test[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.50943396 0.08490566 0.40566038]]\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# Takes a look at all of the probabilities for the three classes/outcomes\n",
    "\n",
    "print(tree_clf.predict_proba([X_test[1]]))\n",
    "print(tree_clf.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Decision Tree Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.54306569 0.52554745 0.5459854 ] \n",
      "\n",
      "[[670 167  76]\n",
      " [191 376  91]\n",
      " [267 157  60]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "\n",
    "cv_score = cross_val_score(tree_clf, X_train, y_train, cv=3, scoring='accuracy')\n",
    "\n",
    "print(cv_score, '\\n')\n",
    "\n",
    "y_train_pred = cross_val_predict(tree_clf, X_train, y_train, cv=3)\n",
    "print(confusion_matrix(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.73      0.66       913\n",
      "           1       0.54      0.57      0.55       658\n",
      "           2       0.26      0.12      0.17       484\n",
      "\n",
      "    accuracy                           0.54      2055\n",
      "   macro avg       0.47      0.48      0.46      2055\n",
      "weighted avg       0.50      0.54      0.51      2055\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Precision, Recall, F1\n",
    "\n",
    "print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "Helpful Links:\n",
    "\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier\n",
    "\n",
    "* https://scikit-learn.org/stable/modules/ensemble.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5583657587548638\n"
     ]
    }
   ],
   "source": [
    "forest_clf = RandomForestClassifier(n_estimators=10, random_state=42, max_depth=5)\n",
    "\n",
    "forest_clf = forest_clf.fit(X_train,y_train)\n",
    "\n",
    "score = forest_clf.score(X_test, y_test)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "# Compares the real result to the predicted result\n",
    "\n",
    "print(y_test.values[1])\n",
    "print(forest_clf.predict([X_test[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.52389671 0.25866391 0.21743938]]\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# Takes a look at all of the probabilities for the three classes/outcomes\n",
    "\n",
    "print(forest_clf.predict_proba([X_test[1]]))\n",
    "print(forest_clf.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.56350365 0.53284672 0.58832117] \n",
      "\n",
      "[[753 141  19]\n",
      " [261 384  13]\n",
      " [314 153  17]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "\n",
    "cv_score = cross_val_score(forest_clf, X_train, y_train, cv=3, scoring='accuracy')\n",
    "\n",
    "print(cv_score, '\\n')\n",
    "\n",
    "y_train_pred = cross_val_predict(forest_clf, X_train, y_train, cv=3)\n",
    "print(confusion_matrix(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.82      0.67       913\n",
      "           1       0.57      0.58      0.57       658\n",
      "           2       0.35      0.04      0.06       484\n",
      "\n",
      "    accuracy                           0.56      2055\n",
      "   macro avg       0.49      0.48      0.44      2055\n",
      "weighted avg       0.51      0.56      0.50      2055\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Precision, Recall, F1\n",
    "\n",
    "print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors\n",
    "\n",
    "Helpful Links:\n",
    "\n",
    "* https://scikit-learn.org/stable/modules/neighbors.html\n",
    "\n",
    "* https://scikit-learn.org/stable/modules/neighbors.html#nearest-neighbors-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5622568093385214\n"
     ]
    }
   ],
   "source": [
    "knn_clf = KNeighborsClassifier(n_neighbors=50)\n",
    "\n",
    "knn_clf.fit(X_train,y_train)\n",
    "\n",
    "score = knn_clf.score(X_test, y_test)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "# Compares the real result to the predicted result\n",
    "\n",
    "print(y_test.values[1])\n",
    "print(knn_clf.predict([X_test[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5 0.2 0.3]]\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# Takes a look at all of the probabilities for the three classes/outcomes\n",
    "\n",
    "print(knn_clf.predict_proba([X_test[1]]))\n",
    "print(knn_clf.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### K Nearest Neighbors Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.55912409 0.54014599 0.55766423] \n",
      "\n",
      "[[764 135  14]\n",
      " [286 359  13]\n",
      " [337 135  12]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "\n",
    "cv_score = cross_val_score(knn_clf, X_train, y_train, cv=3, scoring='accuracy')\n",
    "\n",
    "print(cv_score, '\\n')\n",
    "\n",
    "y_train_pred = cross_val_predict(knn_clf, X_train, y_train, cv=3)\n",
    "print(confusion_matrix(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.84      0.66       913\n",
      "           1       0.57      0.55      0.56       658\n",
      "           2       0.31      0.02      0.05       484\n",
      "\n",
      "    accuracy                           0.55      2055\n",
      "   macro avg       0.48      0.47      0.42      2055\n",
      "weighted avg       0.50      0.55      0.48      2055\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Precision, Recall, F1\n",
    "\n",
    "print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent\n",
    "Helpful Links:\n",
    "\n",
    "* https://scikit-learn.org/stable/modules/sgd.html\n",
    "\n",
    "* https://scikit-learn.org/stable/modules/sgd.html#classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5836575875486382\n"
     ]
    }
   ],
   "source": [
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "\n",
    "sgd_clf.fit(X_train, y_train)\n",
    "\n",
    "score = sgd_clf.score(X_test, y_test)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "# Compares the real result to the predicted result\n",
    "\n",
    "print(y_test.values[1])\n",
    "print(sgd_clf.predict([X_test[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "print(sgd_clf.predict([X_test[1]]))\n",
    "print(sgd_clf.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stochastic Gradient Descent Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5810219  0.51970803 0.56788321] \n",
      "\n",
      "[[688 148  77]\n",
      " [173 392  93]\n",
      " [247 174  63]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "\n",
    "cv_score = cross_val_score(sgd_clf, X_train, y_train, cv=3, scoring='accuracy')\n",
    "\n",
    "print(cv_score, '\\n')\n",
    "\n",
    "y_train_pred = cross_val_predict(sgd_clf, X_train, y_train, cv=3)\n",
    "print(confusion_matrix(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.75      0.68       913\n",
      "           1       0.55      0.60      0.57       658\n",
      "           2       0.27      0.13      0.18       484\n",
      "\n",
      "    accuracy                           0.56      2055\n",
      "   macro avg       0.48      0.49      0.48      2055\n",
      "weighted avg       0.52      0.56      0.53      2055\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Precision, Recall, F1\n",
    "\n",
    "print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Naive Bayes\n",
    "Helpful Links:\n",
    "\n",
    "* https://scikit-learn.org/stable/modules/naive_bayes.html\n",
    "\n",
    "* https://scikit-learn.org/stable/modules/naive_bayes.html#gaussian-naive-bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5486381322957199\n"
     ]
    }
   ],
   "source": [
    "nb_clf = GaussianNB()\n",
    "nb_clf.fit(X_train, y_train)\n",
    "\n",
    "score = nb_clf.score(X_test, y_test)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# Compares the real result to the predicted result\n",
    "\n",
    "print(y_test.values[1])\n",
    "print(nb_clf.predict([X_test[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.34800445 0.43128355 0.220712  ]]\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# Takes a look at all of the probabilities for the three classes/outcomes\n",
    "\n",
    "print(nb_clf.predict_proba([X_test[1]]))\n",
    "print(nb_clf.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Naive Bayes Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.56642336 0.51532847 0.5649635 ] \n",
      "\n",
      "[[648 176  89]\n",
      " [168 417  73]\n",
      " [252 169  63]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "\n",
    "cv_score = cross_val_score(nb_clf, X_train, y_train, cv=3, scoring='accuracy')\n",
    "\n",
    "print(cv_score, '\\n')\n",
    "\n",
    "y_train_pred = cross_val_predict(nb_clf, X_train, y_train, cv=3)\n",
    "print(confusion_matrix(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.71      0.65       913\n",
      "           1       0.55      0.63      0.59       658\n",
      "           2       0.28      0.13      0.18       484\n",
      "\n",
      "    accuracy                           0.55      2055\n",
      "   macro avg       0.48      0.49      0.47      2055\n",
      "weighted avg       0.51      0.55      0.52      2055\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Precision, Recall, F1\n",
    "\n",
    "print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network (Multi Layer Perceptron)\n",
    "\n",
    "Helpful Links:\n",
    "\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier\n",
    "\n",
    "* https://scikit-learn.org/stable/modules/neural_networks_supervised.html#classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5817120622568094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jake\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "nn_clf = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                     hidden_layer_sizes=(5, 2), random_state=42)\n",
    "\n",
    "nn_clf.fit(X_train, y_train)\n",
    "\n",
    "score = nn_clf.score(X_test, y_test)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "# Compares the real result to the predicted result\n",
    "\n",
    "print(y_test.values[1])\n",
    "print(nn_clf.predict([X_test[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.50474647 0.19946518 0.29578835]]\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# Takes a look at all of the probabilities for the three classes/outcomes\n",
    "\n",
    "print(nn_clf.predict_proba([X_test[1]]))\n",
    "print(nn_clf.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Neural Network Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jake\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Jake\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Jake\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.59416058 0.57372263 0.57956204] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jake\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Jake\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[737 167   9]\n",
      " [202 454   2]\n",
      " [275 203   6]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jake\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "\n",
    "cv_score = cross_val_score(nn_clf, X_train, y_train, cv=3, scoring='accuracy')\n",
    "\n",
    "print(cv_score, '\\n')\n",
    "\n",
    "y_train_pred = cross_val_predict(nn_clf, X_train, y_train, cv=3)\n",
    "print(confusion_matrix(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.81      0.69       913\n",
      "           1       0.55      0.69      0.61       658\n",
      "           2       0.35      0.01      0.02       484\n",
      "\n",
      "    accuracy                           0.58      2055\n",
      "   macro avg       0.50      0.50      0.44      2055\n",
      "weighted avg       0.53      0.58      0.51      2055\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Precision, Recall, F1\n",
    "\n",
    "print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Method \n",
    "\n",
    "Constructed Using:\n",
    "\n",
    "* Logistics Regression\n",
    "\n",
    "* Decision Tree\n",
    "\n",
    "* Stochastic Gradient Descent\n",
    "\n",
    "* Neural Network\n",
    "\n",
    "(Use the models made above, did NOT make new models for this)\n",
    "\n",
    "Helpful Links:\n",
    "\n",
    "* https://scikit-learn.org/stable/modules/ensemble.html#voting-classifier\n",
    "\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html#sklearn.ensemble.VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jake\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr',\n",
       "                              LogisticRegression(multi_class='ovr',\n",
       "                                                 random_state=42,\n",
       "                                                 solver='sag')),\n",
       "                             ('dt',\n",
       "                              DecisionTreeClassifier(max_depth=5,\n",
       "                                                     random_state=42)),\n",
       "                             ('nn',\n",
       "                              MLPClassifier(alpha=1e-05,\n",
       "                                            hidden_layer_sizes=(5, 2),\n",
       "                                            random_state=42, solver='lbfgs'))])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('dt', tree_clf), ('nn', nn_clf)],\n",
    "    voting='hard')\n",
    "\n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.6186770428015564\n",
      "DecisionTreeClassifier 0.5369649805447471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jake\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier 0.5817120622568094\n",
      "VotingClassifier 0.6108949416342413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jake\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "for clf in (log_clf, tree_clf, nn_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jake\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Jake\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Jake\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.61021898 0.57956204 0.58686131] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jake\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Jake\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[754 144  15]\n",
      " [200 443  15]\n",
      " [297 167  20]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jake\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "\n",
    "cv_score = cross_val_score(voting_clf, X_train, y_train, cv=3, scoring='accuracy')\n",
    "\n",
    "print(cv_score, '\\n')\n",
    "\n",
    "y_train_pred = cross_val_predict(voting_clf, X_train, y_train, cv=3)\n",
    "print(confusion_matrix(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.83      0.70       913\n",
      "           1       0.59      0.67      0.63       658\n",
      "           2       0.40      0.04      0.07       484\n",
      "\n",
      "    accuracy                           0.59      2055\n",
      "   macro avg       0.53      0.51      0.47      2055\n",
      "weighted avg       0.55      0.59      0.53      2055\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Precision, Recall, F1\n",
    "\n",
    "print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 760 entries, 0 to 759\n",
      "Data columns (total 32 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Season                 760 non-null    object \n",
      " 1   Season Encoding        760 non-null    int64  \n",
      " 2   Date                   760 non-null    object \n",
      " 3   YearOfSeason           612 non-null    object \n",
      " 4   Time                   760 non-null    object \n",
      " 5   Time Encoding          760 non-null    int64  \n",
      " 6   HomeTeam               760 non-null    object \n",
      " 7   HomeTeam Encoding      760 non-null    int64  \n",
      " 8   AwayTeam               760 non-null    object \n",
      " 9   AwayTeam Encoding      760 non-null    int64  \n",
      " 10  FTHG                   760 non-null    float64\n",
      " 11  FTAG                   760 non-null    float64\n",
      " 12  FTR                    760 non-null    object \n",
      " 13  FTR Encoding           760 non-null    int64  \n",
      " 14  HTHG                   760 non-null    float64\n",
      " 15  HTAG                   760 non-null    float64\n",
      " 16  HTR                    760 non-null    object \n",
      " 17  Referee                760 non-null    object \n",
      " 18  Referee Encoding       760 non-null    int64  \n",
      " 19  Fouls Called Per Game  760 non-null    float64\n",
      " 20  HS                     760 non-null    float64\n",
      " 21  AS                     760 non-null    float64\n",
      " 22  HST                    760 non-null    float64\n",
      " 23  AST                    760 non-null    float64\n",
      " 24  HF                     760 non-null    float64\n",
      " 25  AF                     760 non-null    float64\n",
      " 26  HC                     760 non-null    float64\n",
      " 27  AC                     760 non-null    float64\n",
      " 28  HY                     760 non-null    float64\n",
      " 29  AY                     760 non-null    float64\n",
      " 30  HR                     760 non-null    float64\n",
      " 31  AR                     760 non-null    float64\n",
      "dtypes: float64(17), int64(6), object(9)\n",
      "memory usage: 190.1+ KB\n"
     ]
    }
   ],
   "source": [
    "time_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features -- Drops FTR and any categorical value \n",
    "X = time_df.drop(columns=[\"Season\", \"YearOfSeason\", \"Time\", \"Date\", \"FTHG\",\"FTAG\" ,\"HomeTeam\", \"AwayTeam\", \"Referee\", \"FTR\", \"FTR Encoding\", \"HTR\", \"Referee\"])\n",
    "\n",
    "# Labels\n",
    "y = time_df[\"FTR Encoding\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splits the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 760 entries, 0 to 759\n",
      "Data columns (total 20 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Season Encoding        760 non-null    int64  \n",
      " 1   Time Encoding          760 non-null    int64  \n",
      " 2   HomeTeam Encoding      760 non-null    int64  \n",
      " 3   AwayTeam Encoding      760 non-null    int64  \n",
      " 4   HTHG                   760 non-null    float64\n",
      " 5   HTAG                   760 non-null    float64\n",
      " 6   Referee Encoding       760 non-null    int64  \n",
      " 7   Fouls Called Per Game  760 non-null    float64\n",
      " 8   HS                     760 non-null    float64\n",
      " 9   AS                     760 non-null    float64\n",
      " 10  HST                    760 non-null    float64\n",
      " 11  AST                    760 non-null    float64\n",
      " 12  HF                     760 non-null    float64\n",
      " 13  AF                     760 non-null    float64\n",
      " 14  HC                     760 non-null    float64\n",
      " 15  AC                     760 non-null    float64\n",
      " 16  HY                     760 non-null    float64\n",
      " 17  AY                     760 non-null    float64\n",
      " 18  HR                     760 non-null    float64\n",
      " 19  AR                     760 non-null    float64\n",
      "dtypes: float64(15), int64(5)\n",
      "memory usage: 118.9 KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season Encoding</th>\n",
       "      <th>Time Encoding</th>\n",
       "      <th>HomeTeam Encoding</th>\n",
       "      <th>AwayTeam Encoding</th>\n",
       "      <th>HTHG</th>\n",
       "      <th>HTAG</th>\n",
       "      <th>Referee Encoding</th>\n",
       "      <th>Fouls Called Per Game</th>\n",
       "      <th>HS</th>\n",
       "      <th>AS</th>\n",
       "      <th>HST</th>\n",
       "      <th>AST</th>\n",
       "      <th>HF</th>\n",
       "      <th>AF</th>\n",
       "      <th>HC</th>\n",
       "      <th>AC</th>\n",
       "      <th>HY</th>\n",
       "      <th>AY</th>\n",
       "      <th>HR</th>\n",
       "      <th>AR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>28</td>\n",
       "      <td>14.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "      <td>15.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>760 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Season Encoding  Time Encoding  HomeTeam Encoding  AwayTeam Encoding  \\\n",
       "0                  0              0                  8                  0   \n",
       "1                  0              2                  6                 21   \n",
       "2                  0              2                 13                 11   \n",
       "3                  0              2                 28                 17   \n",
       "4                  0              1                 27                 12   \n",
       "..               ...            ...                ...                ...   \n",
       "755                3              1                 12                 15   \n",
       "756                3              1                 14                 18   \n",
       "757                3              1                 17                 13   \n",
       "758                3              1                 21                 20   \n",
       "759                3              1                 28                 -1   \n",
       "\n",
       "     HTHG  HTAG  Referee Encoding  Fouls Called Per Game    HS    AS   HST  \\\n",
       "0     0.0   1.0                 7                   14.0   5.0  13.0   2.0   \n",
       "1     1.0   0.0                27                   14.0   5.0   9.0   3.0   \n",
       "2     3.0   2.0                28                   14.0  22.0   6.0   6.0   \n",
       "3     0.0   0.0                11                   14.0  15.0  15.0   3.0   \n",
       "4     0.0   0.0                10                   15.0   7.0  13.0   1.0   \n",
       "..    ...   ...               ...                    ...   ...   ...   ...   \n",
       "755   0.0   0.0                16                   13.0  14.0   7.0   3.0   \n",
       "756   2.0   0.0                25                   15.0  31.0   5.0  10.0   \n",
       "757   1.0   1.0                10                   15.0   3.0  14.0   2.0   \n",
       "758   0.0   1.0                 3                   13.0  13.0   5.0   4.0   \n",
       "759   0.0   0.0                28                   14.0  10.0  13.0   1.0   \n",
       "\n",
       "     AST    HF    AF   HC   AC   HY   AY   HR   AR  \n",
       "0    6.0  12.0  12.0  2.0  3.0  2.0  2.0  0.0  0.0  \n",
       "1    5.0  14.0  11.0  7.0  3.0  2.0  1.0  0.0  0.0  \n",
       "2    3.0   9.0   6.0  9.0  0.0  1.0  0.0  0.0  0.0  \n",
       "3    2.0  13.0   7.0  8.0  7.0  2.0  2.0  0.0  0.0  \n",
       "4    7.0  12.0   9.0  2.0  5.0  1.0  1.0  0.0  0.0  \n",
       "..   ...   ...   ...  ...  ...  ...  ...  ...  ...  \n",
       "755  3.0  12.0  11.0  3.0  3.0  1.0  4.0  1.0  0.0  \n",
       "756  4.0   7.0   4.0  9.0  0.0  1.0  1.0  0.0  0.0  \n",
       "757  6.0  11.0   5.0  2.0  4.0  1.0  0.0  0.0  0.0  \n",
       "758  3.0   9.0  16.0  9.0  1.0  0.0  1.0  0.0  0.0  \n",
       "759  4.0  16.0  13.0  0.0  7.0  2.0  1.0  0.0  0.0  \n",
       "\n",
       "[760 rows x 20 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      0\n",
       "2      0\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "755    1\n",
       "756    0\n",
       "757    1\n",
       "758    0\n",
       "759    2\n",
       "Name: FTR Encoding, Length: 760, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "Helpful links:\n",
    "\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "\n",
    "* https://medium.com/analytics-vidhya/l1-vs-l2-regularization-which-is-better-d01068e6658c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6381578947368421\n"
     ]
    }
   ],
   "source": [
    "log_clf = LogisticRegression(random_state=0, penalty='l2', solver='sag', multi_class='ovr')\n",
    "log_clf = log_clf.fit(X_train, y_train)\n",
    "\n",
    "score = log_clf.score(X_test, y_test)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# Compares the real result to the predicted result\n",
    "\n",
    "print(y_test.values[1])\n",
    "print(log_clf.predict([X_test[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00392731 0.94436212 0.05171058]]\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# Takes a look at all of the probabilities for the three classes\n",
    "\n",
    "print(log_clf.predict_proba([X_test[1]]))\n",
    "print(log_clf.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.67487685 0.64039409 0.68811881] \n",
      "\n",
      "[[209  32  16]\n",
      " [ 26 173  15]\n",
      " [ 65  48  24]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "\n",
    "cv_score = cross_val_score(log_clf, X_train, y_train, cv=3, scoring='accuracy')\n",
    "\n",
    "print(cv_score, '\\n')\n",
    "\n",
    "y_train_pred = cross_val_predict(log_clf, X_train, y_train, cv=3)\n",
    "print(confusion_matrix(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.81      0.75       257\n",
      "           1       0.68      0.81      0.74       214\n",
      "           2       0.44      0.18      0.25       137\n",
      "\n",
      "    accuracy                           0.67       608\n",
      "   macro avg       0.61      0.60      0.58       608\n",
      "weighted avg       0.63      0.67      0.63       608\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Precision, Recall, F1\n",
    "\n",
    "print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "\n",
    "Helpful Links:\n",
    "\n",
    "* https://scikit-learn.org/stable/modules/tree.html\n",
    "\n",
    "* https://scikit-learn.org/stable/modules/tree.html#classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5855263157894737\n"
     ]
    }
   ],
   "source": [
    "tree_clf = DecisionTreeClassifier(max_depth=5)\n",
    "tree_clf.fit(X_train,y_train)\n",
    "\n",
    "score = tree_clf.score(X_test, y_test)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# Compares the real result to the predicted result\n",
    "\n",
    "print(y_test.values[1])\n",
    "print(tree_clf.predict([X_test[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.08333333 0.58333333 0.33333333]]\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# Takes a look at all of the probabilities for the three classes\n",
    "\n",
    "print(tree_clf.predict_proba([X_test[1]]))\n",
    "print(tree_clf.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Decision Tree Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5862069  0.55665025 0.58910891] \n",
      "\n",
      "[[193  27  37]\n",
      " [ 58 130  26]\n",
      " [ 77  34  26]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "\n",
    "cv_score = cross_val_score(tree_clf, X_train, y_train, cv=3, scoring='accuracy')\n",
    "\n",
    "print(cv_score, '\\n')\n",
    "\n",
    "y_train_pred = cross_val_predict(tree_clf, X_train, y_train, cv=3)\n",
    "print(confusion_matrix(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.75      0.66       257\n",
      "           1       0.68      0.61      0.64       214\n",
      "           2       0.29      0.19      0.23       137\n",
      "\n",
      "    accuracy                           0.57       608\n",
      "   macro avg       0.52      0.52      0.51       608\n",
      "weighted avg       0.55      0.57      0.56       608\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Precision, Recall, F1\n",
    "\n",
    "print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "Helpful Links:\n",
    "\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier\n",
    "\n",
    "* https://scikit-learn.org/stable/modules/ensemble.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.631578947368421\n"
     ]
    }
   ],
   "source": [
    "forest_clf = RandomForestClassifier(n_estimators=10, random_state=42, max_depth=5)\n",
    "\n",
    "forest_clf = forest_clf.fit(X_train,y_train)\n",
    "\n",
    "score = forest_clf.score(X_test, y_test)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# Compares the real result to the predicted result\n",
    "\n",
    "print(y_test.values[1])\n",
    "print(forest_clf.predict([X_test[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.14827571 0.72301287 0.12871142]]\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# Takes a look at all of the probabilities for the three classes\n",
    "\n",
    "print(forest_clf.predict_proba([X_test[1]]))\n",
    "print(forest_clf.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.63054187 0.60591133 0.65841584] \n",
      "\n",
      "[[210  35  12]\n",
      " [ 42 163   9]\n",
      " [ 74  52  11]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "\n",
    "cv_score = cross_val_score(forest_clf, X_train, y_train, cv=3, scoring='accuracy')\n",
    "\n",
    "print(cv_score, '\\n')\n",
    "\n",
    "y_train_pred = cross_val_predict(forest_clf, X_train, y_train, cv=3)\n",
    "print(confusion_matrix(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.82      0.72       257\n",
      "           1       0.65      0.76      0.70       214\n",
      "           2       0.34      0.08      0.13       137\n",
      "\n",
      "    accuracy                           0.63       608\n",
      "   macro avg       0.55      0.55      0.52       608\n",
      "weighted avg       0.58      0.63      0.58       608\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Precision, Recall, F1\n",
    "\n",
    "print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors\n",
    "\n",
    "Helpful Links:\n",
    "\n",
    "* https://scikit-learn.org/stable/modules/neighbors.html\n",
    "\n",
    "* https://scikit-learn.org/stable/modules/neighbors.html#nearest-neighbors-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6118421052631579\n"
     ]
    }
   ],
   "source": [
    "knn_clf = KNeighborsClassifier(n_neighbors=50)\n",
    "\n",
    "knn_clf.fit(X_train,y_train)\n",
    "\n",
    "score = knn_clf.score(X_test, y_test)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# Compares the real result to the predicted result\n",
    "\n",
    "print(y_test.values[1])\n",
    "print(knn_clf.predict([X_test[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.04 0.92 0.04]]\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# Takes a look at all of the probabilities for the three classes\n",
    "\n",
    "print(knn_clf.predict_proba([X_test[1]]))\n",
    "print(knn_clf.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### K Nearest Neighbors Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.62068966 0.59605911 0.6039604 ] \n",
      "\n",
      "[[216  38   3]\n",
      " [ 61 150   3]\n",
      " [ 85  49   3]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "\n",
    "cv_score = cross_val_score(knn_clf, X_train, y_train, cv=3, scoring='accuracy')\n",
    "\n",
    "print(cv_score, '\\n')\n",
    "\n",
    "y_train_pred = cross_val_predict(knn_clf, X_train, y_train, cv=3)\n",
    "print(confusion_matrix(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.84      0.70       257\n",
      "           1       0.63      0.70      0.67       214\n",
      "           2       0.33      0.02      0.04       137\n",
      "\n",
      "    accuracy                           0.61       608\n",
      "   macro avg       0.52      0.52      0.47       608\n",
      "weighted avg       0.55      0.61      0.54       608\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Precision, Recall, F1\n",
    "\n",
    "print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent\n",
    "\n",
    "Helpful Links:\n",
    "\n",
    "* https://scikit-learn.org/stable/modules/sgd.html\n",
    "\n",
    "* https://scikit-learn.org/stable/modules/sgd.html#classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5131578947368421\n"
     ]
    }
   ],
   "source": [
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "\n",
    "sgd_clf.fit(X_train, y_train)\n",
    "\n",
    "score = sgd_clf.score(X_test, y_test)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# Compares the real result to the predicted result\n",
    "\n",
    "\n",
    "print(y_test.values[1])\n",
    "print(sgd_clf.predict([X_test[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# Takes a look at all of the probabilities for the three classes\n",
    "\n",
    "print(sgd_clf.predict([X_test[1]]))\n",
    "print(sgd_clf.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stochastic Gradient Descent Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.64039409 0.591133   0.6039604 ] \n",
      "\n",
      "[[203  25  29]\n",
      " [ 44 143  27]\n",
      " [ 74  37  26]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "\n",
    "cv_score = cross_val_score(sgd_clf, X_train, y_train, cv=3, scoring='accuracy')\n",
    "\n",
    "print(cv_score, '\\n')\n",
    "\n",
    "y_train_pred = cross_val_predict(sgd_clf, X_train, y_train, cv=3)\n",
    "print(confusion_matrix(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.79      0.70       257\n",
      "           1       0.70      0.67      0.68       214\n",
      "           2       0.32      0.19      0.24       137\n",
      "\n",
      "    accuracy                           0.61       608\n",
      "   macro avg       0.55      0.55      0.54       608\n",
      "weighted avg       0.58      0.61      0.59       608\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Precision, Recall, F1\n",
    "\n",
    "print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes\n",
    "\n",
    "Helpful Links:\n",
    "\n",
    "* https://scikit-learn.org/stable/modules/naive_bayes.html\n",
    "\n",
    "* https://scikit-learn.org/stable/modules/naive_bayes.html#gaussian-naive-bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.618421052631579\n"
     ]
    }
   ],
   "source": [
    "nb_clf = GaussianNB()\n",
    "nb_clf.fit(X_train, y_train)\n",
    "\n",
    "score = nb_clf.score(X_test, y_test)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# Compares the real result to the predicted result\n",
    "\n",
    "print(y_test.values[1])\n",
    "print(nb_clf.predict([X_test[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# Takes a look at all of the probabilities for the three classes\n",
    "\n",
    "print(nb_clf.predict([X_test[1]]))\n",
    "print(nb_clf.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Naive Bayes Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.65024631 0.5862069  0.52970297] \n",
      "\n",
      "[[167  37  53]\n",
      " [ 17 151  46]\n",
      " [ 54  43  40]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "\n",
    "cv_score = cross_val_score(nb_clf, X_train, y_train, cv=3, scoring='accuracy')\n",
    "\n",
    "print(cv_score, '\\n')\n",
    "\n",
    "y_train_pred = cross_val_predict(nb_clf, X_train, y_train, cv=3)\n",
    "print(confusion_matrix(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**250** mislabeled observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network (Multi Layer Perceptron)\n",
    "\n",
    "Helpful Links:\n",
    "\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier\n",
    "\n",
    "* https://scikit-learn.org/stable/modules/neural_networks_supervised.html#classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.618421052631579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jake\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "nn_clf = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                     hidden_layer_sizes=(5, 2), random_state=1)\n",
    "\n",
    "nn_clf.fit(X_train, y_train)\n",
    "\n",
    "score = nn_clf.score(X_test, y_test)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# Compares the real result to the predicted result\n",
    "\n",
    "print(y_test.values[1])\n",
    "print(nn_clf.predict([X_test[1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Neural Network Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jake\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Jake\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Jake\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Jake\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.63054187 0.56650246 0.6039604 ] \n",
      "\n",
      "[[182  43  32]\n",
      " [ 29 158  27]\n",
      " [ 53  59  25]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jake\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Jake\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "\n",
    "cv_score = cross_val_score(nn_clf, X_train, y_train, cv=3, scoring='accuracy')\n",
    "\n",
    "print(cv_score, '\\n')\n",
    "\n",
    "y_train_pred = cross_val_predict(nn_clf, X_train, y_train, cv=3)\n",
    "print(confusion_matrix(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Method\n",
    "\n",
    "Constructed Using:\n",
    "\n",
    "* Logistics Regression\n",
    "\n",
    "* Random Forest\n",
    "\n",
    "* KNN\n",
    "\n",
    "* Naive Bayes\n",
    "\n",
    "* Neural Network\n",
    "\n",
    "(Use the models made above, did NOT make new models for this)\n",
    "\n",
    "Helpful Links:\n",
    "\n",
    "* https://scikit-learn.org/stable/modules/ensemble.html#voting-classifier\n",
    "\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html#sklearn.ensemble.VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jake\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr',\n",
       "                              LogisticRegression(multi_class='ovr',\n",
       "                                                 random_state=0,\n",
       "                                                 solver='sag')),\n",
       "                             ('rf',\n",
       "                              RandomForestClassifier(max_depth=5,\n",
       "                                                     n_estimators=10,\n",
       "                                                     random_state=42)),\n",
       "                             ('knn', KNeighborsClassifier(n_neighbors=50)),\n",
       "                             ('nb', GaussianNB()),\n",
       "                             ('nn',\n",
       "                              MLPClassifier(alpha=1e-05,\n",
       "                                            hidden_layer_sizes=(5, 2),\n",
       "                                            random_state=1, solver='lbfgs'))])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('rf', forest_clf), ('knn', knn_clf), ('nb', nb_clf), ('nn', nn_clf)],\n",
    "    voting='hard')\n",
    "\n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.6381578947368421\n",
      "RandomForestClassifier 0.631578947368421\n",
      "MLPClassifier 0.618421052631579\n",
      "KNeighborsClassifier 0.6118421052631579\n",
      "GaussianNB 0.618421052631579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jake\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Jake\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier 0.625\n"
     ]
    }
   ],
   "source": [
    "for clf in (log_clf, forest_clf, nn_clf,knn_clf, nb_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ensemble Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jake\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Jake\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Jake\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Jake\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.65517241 0.61576355 0.67326733] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jake\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Jake\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[218  33   6]\n",
      " [ 40 167   7]\n",
      " [ 77  51   9]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "\n",
    "cv_score = cross_val_score(voting_clf, X_train, y_train, cv=3, scoring='accuracy')\n",
    "\n",
    "print(cv_score, '\\n')\n",
    "\n",
    "y_train_pred = cross_val_predict(voting_clf, X_train, y_train, cv=3)\n",
    "print(confusion_matrix(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
